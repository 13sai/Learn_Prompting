% CoT
@misc{wei2022chain,
    title={Chain of Thought Prompting Elicits Reasoning in Large Language Models},
    author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
    year={2022},
    eprint={2201.11903},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

0-shot CoT
@misc{kojima2022large,
    title={Large Language Models are Zero-Shot Reasoners},
    author={Takeshi Kojima and Shixiang Shane Gu and Machel Reid and Yutaka Matsuo and Yusuke Iwasawa},
    year={2022},
    eprint={2205.11916},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

% definition of prompting
@article{shin2020autoprompt,
   title={AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts},
   url={http://dx.doi.org/10.18653/v1/2020.emnlp-main.346},
   DOI={10.18653/v1/2020.emnlp-main.346},
   journal={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
   publisher={Association for Computational Linguistics},
   author={Shin, Taylor and Razeghi, Yasaman and Logan IV, Robert L. and Wallace, Eric and Singh, Sameer},
   year={2020} }

% gpt3
@misc{brown2020language,
    title={Language Models are Few-Shot Learners},
    author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
    year={2020},
    eprint={2005.14165},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

% gpt3 instruct
@misc{ouyang2022training,
    title={Training language models to follow instructions with human feedback},
    author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
    year={2022},
    eprint={2203.02155},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

% showing similar training examples
@misc{liu2021makes,
    title={What Makes Good In-Context Examples for GPT-$3$?},
    author={Jiachang Liu and Dinghan Shen and Yizhe Zhang and Bill Dolan and Lawrence Carin and Weizhu Chen},
    year={2021},
    eprint={2101.06804},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

% soft prompting
@misc{lester2021power,
    title={The Power of Scale for Parameter-Efficient Prompt Tuning},
    author={Brian Lester and Rami Al-Rfou and Noah Constant},
    year={2021},
    eprint={2104.08691},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

% discretized soft promting (interpreting)
@misc{khashabi2021prompt,
    title={Prompt Waywardness: The Curious Case of Discretized Interpretation of Continuous Prompts},
    author={Daniel Khashabi and Shane Lyu and Sewon Min and Lianhui Qin and Kyle Richardson and Sean Welleck and Hannaneh Hajishirzi and Tushar Khot and Ashish Sabharwal and Sameer Singh and Yejin Choi},
    year={2021},
    eprint={2112.08348},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

% generate knowledge
@misc{liu2021generated,
    title={Generated Knowledge Prompting for Commonsense Reasoning},
    author={Jiacheng Liu and Alisa Liu and Ximing Lu and Sean Welleck and Peter West and Ronan Le Bras and Yejin Choi and Hannaneh Hajishirzi},
    year={2021},
    eprint={2110.08387},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

% analyzing harm
@misc{si2022prompting,
    title={Prompting GPT-3 To Be Reliable},
    author={Chenglei Si and Zhe Gan and Zhengyuan Yang and Shuohang Wang and Jianfeng Wang and Jordan Boyd-Graber and Lijuan Wang},
    year={2022},
    eprint={2210.09150},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}